{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MuRIL Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/muril-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print('Loading model')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
    "print('Model Loaded')\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print('device check done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamil dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"роЪро┐роХро┐роЪрпНроЪрпИ роиройрпНро▒ро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНродродрпБ\",  # Treatment worked well\n",
    "        \"рооро░рпБроирпНродрпБ роХрпКроЯрпБродрпНрод рокро┐ро▒роХрпБ ро╡ро▓ро┐ роЕродро┐роХро░ро┐родрпНродродрпБ\",  # Pain increased after medication\n",
    "        \"рооро░рпБродрпНродрпБро╡рооройрпИ роЪрпЗро╡рпИ роЪро┐ро▒рокрпНрокро╛роХ роЗро░рпБроирпНродродрпБ\",  # Hospital service was excellent\n",
    "        \"роХро╛ропрпНроЪрпНроЪро▓рпН роХрпБро▒рпИропро╡ро┐ро▓рпНро▓рпИ\",  # Fever didnтАЩt reduce\n",
    "        \"рооро░рпБродрпНродрпБро╡ро░рпНроХро│рпН роХро╡ройрооро╛роХ рокро░ро╛рооро░ро┐родрпНродройро░рпН\"  # Doctors cared attentively\n",
    "    ],\n",
    "    \"label\": [1, 0, 1, 0, 1]  # 1 = Positive, 0 = Negative\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Splitting into train and eval \n",
    "train_dataset = dataset.select(range(4))\n",
    "eval_dataset = dataset.select(range(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b9802a0d31409f8344b862404e87db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e431a9e5002416aa9a5d82976b25db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preprocess Tamil Text\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,  \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "encoded_train = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "encoded_eval = eval_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Renaming 'label' to 'labels' \n",
    "encoded_train = encoded_train.rename_column(\"label\", \"labels\")\n",
    "encoded_eval = encoded_eval.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 okay\n",
      " 2 okay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gautham.s\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ЁЯдЧ Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 okay\n"
     ]
    }
   ],
   "source": [
    "#Defining Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "print(' 1 okay')\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=r\".\\muril_tamil_output\",\n",
    "    num_train_epochs= 6,  \n",
    "    per_device_train_batch_size=1,  \n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=2,  \n",
    "    weight_decay=0.01,\n",
    "    logging_dir=r\".\\muril_tamil_logs\",\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=2,  \n",
    "    fp16=False,  # CPU-only\n",
    ")\n",
    "\n",
    "print(' 2 okay')\n",
    "\n",
    "# 6. Initialize and Train Model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train,\n",
    "    eval_dataset=encoded_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(' 3 okay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MuRIL fine-tuning for Tamil sentiment classification...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79035bcaa884ad9a17fcf58b6117ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.69, 'grad_norm': 0.19738243520259857, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.6939, 'grad_norm': 0.14221253991127014, 'learning_rate': 5e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359f9f84ad3349e2b1d27bc30922bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6943386793136597, 'eval_accuracy': 0.0, 'eval_runtime': 1.0004, 'eval_samples_per_second': 1.0, 'eval_steps_per_second': 1.0, 'epoch': 1.0}\n",
      "{'loss': 0.6922, 'grad_norm': 0.12722145020961761, 'learning_rate': 4.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.6925, 'grad_norm': 0.14881107211112976, 'learning_rate': 4e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06502b31dad049dd9aa0e5a85b54eb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.693554699420929, 'eval_accuracy': 0.0, 'eval_runtime': 0.7289, 'eval_samples_per_second': 1.372, 'eval_steps_per_second': 1.372, 'epoch': 2.0}\n",
      "{'loss': 0.6904, 'grad_norm': 0.13887521624565125, 'learning_rate': 3.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6908, 'grad_norm': 0.18203774094581604, 'learning_rate': 3e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef54f31e41064459be076fac7227eba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6931657791137695, 'eval_accuracy': 0.0, 'eval_runtime': 0.8644, 'eval_samples_per_second': 1.157, 'eval_steps_per_second': 1.157, 'epoch': 3.0}\n",
      "{'loss': 0.69, 'grad_norm': 0.21788634359836578, 'learning_rate': 2.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6894, 'grad_norm': 0.16752812266349792, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1373139d3ae4a8e9ee5e30393ed3af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.693187415599823, 'eval_accuracy': 0.0, 'eval_runtime': 0.7104, 'eval_samples_per_second': 1.408, 'eval_steps_per_second': 1.408, 'epoch': 4.0}\n",
      "{'loss': 0.6888, 'grad_norm': 0.18691694736480713, 'learning_rate': 1.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6876, 'grad_norm': 0.17849470674991608, 'learning_rate': 1e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba27d32bdfe4cfaaadc94399c60da73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934930086135864, 'eval_accuracy': 0.0, 'eval_runtime': 1.0519, 'eval_samples_per_second': 0.951, 'eval_steps_per_second': 0.951, 'epoch': 5.0}\n",
      "{'loss': 0.6845, 'grad_norm': 0.21268273890018463, 'learning_rate': 5e-06, 'epoch': 5.5}\n",
      "{'loss': 0.6871, 'grad_norm': 0.1666143834590912, 'learning_rate': 0.0, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d58e1de5d46446ba96cf9ad033bea25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934459805488586, 'eval_accuracy': 0.0, 'eval_runtime': 1.0962, 'eval_samples_per_second': 0.912, 'eval_steps_per_second': 0.912, 'epoch': 6.0}\n",
      "{'train_runtime': 397.7181, 'train_samples_per_second': 0.06, 'train_steps_per_second': 0.03, 'train_loss': 0.6897701869408289, 'epoch': 6.0}\n",
      "Fine-tuning completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting MuRIL fine-tuning for Tamil sentiment classification...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(r\".\\muril_tamil_model\")\n",
    "tokenizer.save_pretrained(r\".\\muril_tamil_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference Function\n",
    "def predict_sentiment(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)\n",
    "    sentiment = \"Positive\" if torch.argmax(probs) == 1 else \"Negative\"\n",
    "    return sentiment, probs[0][1].item()  # Return sentiment and positive probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loadomg fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(r\".\\muril_tamil_model\")\n",
    "loaded_model.to(device)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(r\".\\muril_tamil_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Text: роЪро┐роХро┐роЪрпНроЪрпИ роЪро░ро┐ропро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНропро╡ро┐ро▓рпНро▓рпИ, (Treatment didn't work well)\n",
      "Sentiment: Negative, Positive Probability: 0.500\n",
      "\n",
      "Example 2\n",
      "Text: роЪро┐роХро┐роЪрпНроЪрпИ роиройрпНро▒ро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНродродрпБ, рооро░рпБродрпНродрпБро╡ро░рпНроХро│рпН рооро┐роХро╡рпБроорпН роЙродро╡ро┐ройро╛ро░рпНроХро│рпН, (Treatment worked well, doctors helped a lot)\n",
      "Sentiment: Positive, Positive Probability: 0.501\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "print('Example 1')\n",
    "tamil_note = \"роЪро┐роХро┐роЪрпНроЪрпИ роЪро░ро┐ропро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНропро╡ро┐ро▓рпНро▓рпИ\"  \n",
    "tn = \"Treatment didn't work well\"\n",
    "sentiment, prob = predict_sentiment(tamil_note, loaded_model, loaded_tokenizer)\n",
    "print(f\"Text: {tamil_note}, ({tn})\")\n",
    "print(f\"Sentiment: {sentiment}, Positive Probability: {prob:.3f}\")\n",
    "\n",
    "tamil_note1 = \"роЪро┐роХро┐роЪрпНроЪрпИ роиройрпНро▒ро╛роХ ро╡рпЗро▓рпИ роЪрпЖропрпНродродрпБ, рооро░рпБродрпНродрпБро╡ро░рпНроХро│рпН рооро┐роХро╡рпБроорпН роЙродро╡ро┐ройро╛ро░рпНроХро│рпН\"  \n",
    "tn1 = \"Treatment worked well, doctors helped a lot\"\n",
    "sentiment1, prob1 = predict_sentiment(tamil_note1, loaded_model, loaded_tokenizer)\n",
    "print(f\"\\nExample 2\")\n",
    "print(f\"Text: {tamil_note1}, ({tn1})\")\n",
    "print(f\"Sentiment: {sentiment1}, Positive Probability: {prob1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
